<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>相同弦长的本原勾股数组数分布规律初探</title>
    <url>/%E7%9B%B8%E5%90%8C%E5%BC%A6%E9%95%BF%E7%9A%84%E6%9C%AC%E5%8E%9F%E5%8B%BE%E8%82%A1%E6%95%B0%E7%BB%84%E6%95%B0%E5%88%86%E5%B8%83%E8%A7%84%E5%BE%8B%E5%88%9D%E6%8E%A2/</url>
    <content><![CDATA[<style>
table {
margin: auto;
}
</style>

<p>&emsp;  在《数论概论》中，关于本原勾股数组有这样一道练习题：</p>
<div align="center">
<img src="/%E7%9B%B8%E5%90%8C%E5%BC%A6%E9%95%BF%E7%9A%84%E6%9C%AC%E5%8E%9F%E5%8B%BE%E8%82%A1%E6%95%B0%E7%BB%84%E6%95%B0%E5%88%86%E5%B8%83%E8%A7%84%E5%BE%8B%E5%88%9D%E6%8E%A2/0_1.jpg">
</div>

<p>&emsp; 题意为：对于本原勾股数组，当弦长 $c$ 取何值时，可以分解为多组本原勾股数 $(a_i,b_i)$。进一步，分析本原勾股数的组数 $\phi(c)$ 的分布规律。</p>
<p>&emsp; 本文利用最基本的数论求解上述问题，不够严谨，仅为兴趣探讨。</p>
<a id="more"></a>
<h2 id="1-本原勾股数组简介"><a href="#1-本原勾股数组简介" class="headerlink" title="1 本原勾股数组简介"></a>1 本原勾股数组简介</h2><p>&emsp; 详见相关初等数论书籍，一般的，称<strong>最大公因数</strong>为1的勾股数组为本原勾股数组，即：当且仅当 $(a,b,c)=1$时，称勾股数组 $a,b,c$ 为一组本原勾股数组。<br>&emsp; 本原勾股数组的勾股关系可用下式表示：</p>
<script type="math/tex; mode=display">\left\{\begin{array}{l}
a=s\cdot t \\
b=(s^{2}-t^{2})/2 \\
c=(s^{2}+t^{2})/2 \tag{0}
\end{array}\right.</script><p>&emsp; 式中，$s,t$ 为互质的奇数，并不妨令$s&gt;t$。<br>&emsp; 此外，观察表达式容易发现一些基本事实，例如 $2\mid b$，$c^2 \equiv 1mod(4)$ 等等。</p>
<h2 id="2-问题的求解"><a href="#2-问题的求解" class="headerlink" title="2 问题的求解"></a>2 问题的求解</h2><p><br></p>
<h3 id="2-1-一个引理"><a href="#2-1-一个引理" class="headerlink" title="2.1 一个引理"></a>2.1 一个引理</h3><p><em>引理：对于奇素数 $p$，当且仅当$p\equiv 1mod(4)$时，$p$可以<strong>唯一</strong>的分解为两个整数的平方和。即 $p=u^2+v^2$</em></p>
<p>&emsp; 该引理可以分为两个部分进行证明，一个部分是$p\equiv 1mod(4)$与$p$可分解的<strong>充要性</strong>，另一个是 $p$ 分解为两数平方和的<strong>唯一性</strong>。<br>&emsp; 关于前者充要性，其必要性是显然的，充分性常用二次剩余结合费马下降法证明。（$(\frac{-1}{p})=1$）<br>&emsp; 对于后者唯一性，不同参考书目中也有相关证明，本文推导的唯一性证明如下：</p>
<p>&emsp; 假设素数 $p$ 可以分解成两组不同的整数的平方和，即：</p>
<script type="math/tex; mode=display">p=u_1^2+v_1^2=u_2^2+v_2^2</script><p>&emsp; 上式中不妨设 $u_1&gt;u_2&gt;v_2&gt;v_1&gt;0$，那么有(1)式为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
p^2 &=(u_1^2+v_1^2)(u_2^2+v_2^2)\\
&=(u_1u_2+v_1v_2)^2+(u_1v_2-u_2v_1)^2\\
&=(u_1v_2+u_2v_1)^2+(u_1u_2-v_1v_2)^2  \ \ (1)
\end{aligned}</script><p>&emsp; 将(1)中平方项因子提取相乘构造$M$，可以发现：</p>
<script type="math/tex; mode=display">
\begin{aligned}
M &= (u_1u_2+v_1v_2)(u_1u_2-v_1v_2)(u_1v_2+u_2v_1)(u_1v_2-u_2v_1)\\
&=(u_1^2u_2^2-v_1^2v_2^2)(u_1^2v_2^2-u_2^2v_1^2)\\
&=(u_1^4+v_1^4)u_2^2v_2^2-(u_2^4+v_2^4)u_1^2v_1^2\\
&=[(u_1^2+v_1^2)^2-2u_1^2v_1^2]u_2^2v_2^2 -[(u_2^2+v_2^2)^2-2u_2^2v_2^2]u_1^2v_1^2 \\
&=p^2u_2^2v_2^2-p^2u_1^2v_1^2 \\
&=p^2(u_2^2v_2^2-u_1^2v_1^2)
\end{aligned}</script><p>&emsp; 由初等不等式知 $(u_2^2v_2^2-u_1^2v_1^2)&gt;0$</p>
<script type="math/tex; mode=display">\therefore p\mid M</script><p>&emsp; 又 $\because$ $p$ 是素数，所以有（2）式为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
p&\mid (u_1u_2+v_1v_2)\ or\\
p&\mid (u_1u_2-v_1v_2)\ or\\
p&\mid (u_1v_2+u_2v_1)\ or\\
p&\mid (u_1v_2-u_2v_1)  \ \ \  (2)
\end{aligned}</script><p>&emsp; 又由(1)可知：  </p>
<script type="math/tex; mode=display">
p\ge(u_1u_2+v_1v_2),(u_1u_2-v_1v_2),(u_1v_2+u_2v_1),(u_1v_2-u_2v_1)  \tag{3}</script><p>&emsp; 对比(2)、(3)式可知：  </p>
<script type="math/tex; mode=display">
\left\{\begin{array}{r}
u_1u_2+v_1v_2=p \\
u_1v_2-u_2v_1=0
\end{array}\right.
or \ 
\left\{\begin{array}{r}
u_1v_2+u_2v_1=p\\
u_1u_2-v_1v_2=0
\end{array}\right.</script><p>&emsp; 以上两式都可以得到 $u_1=u_2, v_1=v_2$。至此素数 $p$ 分解的唯一性得证。</p>
<h3 id="2-2-c-的规律"><a href="#2-2-c-的规律" class="headerlink" title="2.2 $c$ 的规律"></a>2.2 $c$ 的规律</h3><p><br></p>
<p>&emsp; 前已说明 $c$ 是奇数，现在将 $c$ 质因数分解：</p>
<script type="math/tex; mode=display">c=\prod_{i=1}^n p_i^{\alpha_i}\prod_{j=1}^m q_i^{\beta_i} \tag{4}</script><p>&emsp; 上式中 $p_i\equiv 1mod(4)$ ，$q_i\equiv -1mod(4)$ 为 $c$ 的质因子，$\alpha_i$，$\beta_i$ 为对应质因子的次数。<br>&emsp; 对于本原勾股数组中 $c$ ，接下来说明两个结论（非严格论证，絮絮叨叨）：</p>
<ul>
<li>本原勾股数组要求 $c$ 中没有 $q_i$项，$c$ 全部由 $\equiv 1mod(4)$的 $p_i$ 构成。  </li>
<li>$c$ 能够分解出的本原勾股数组的组数 $\phi(c)=2^{n-1}$，和指数 $\alpha_i$ 无关。</li>
</ul>
<p>&emsp; 对于结论1，首先利用 $c=(s^{2}+t^{2})/2$，并对 $s,t$ 模8分析可知 $c\equiv 1mod(4)$（ 这一点也可以用 $a=2mn;\ b=m^2-n^2;\ c=m^2+n^2$ 得到 ）。所以<strong>对于非本原勾股数组要求 $2\mid \beta_i$</strong>，而对于本原勾股数组，从后面的分解构造过程可以发现 $\beta_i=0$。<br>&emsp; 对于结论2，首先说明 $p_i^{\alpha_i}$能够分解的本原组数和 $p_i$相同：当${\alpha_i}\le2$ 时，结论显然；当${\alpha_i}&gt;3$ 时，类似于引理的证明可知本原的分解唯一（ 否则 $a,b$ 应同为 $p_i$ 的倍数 ）。<br>&emsp; 其次说明 $\alpha_i=1$ 时 $\phi(c)=2^{n-1}$ 与本原勾股数组的分解构造过程：</p>
<p>&emsp;  由引理，对于模4余1的素数 $p_i$ 可令： $p_i=u_i^2+v_i^2$，<br>&emsp;  设 $c_{k}=a_k^2+b_k^2$，且 $c_{1}=p_1=u_1^2+v_1^2$，则有（*）为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
c_{k}=c_{k-1}p_k &=(a_{k-1}^2+b_{k-1}^2)(u_k^2+v_k^2) \\
&=(a_{k-1}u_k+b_{k-1}v_k)^2+(a_{k-1}v_k-u_kb_{k-1})^2\\
&=(a_{k-1}v_k+u_kb_{k-1})^2+(a_{k-1}u_k-b_{k-1}v_k)^2  
\end{aligned}</script><p>&emsp; 对比也就有：</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{r}
a_k=a_{k-1}u_k+b_{k-1}v_k \\
b_k=a_{k-1}v_k-b_{k-1}u_k
\end{array}\right.
or \ 
\left\{\begin{array}{r}
a_k=a_{k-1}v_k+b_{k-1}u_k \\
b_k=a_{k-1}u_k-b_{k-1}v_k
\end{array}\right.</script><p>&emsp; 对于 $k=1 \sim n-1$ 重复上诉过程，最后得到 $c_{n}=a_n^2+b_n^2$ 。</p>
<p>&emsp; 上述即为本文所述<strong>本原勾股数组分解构造过程</strong>，$p_i$的每一次相乘都有两种不同的 $(a_k,b_k)$，并且有 $(a_k,b_k)=1$，总共进行 $n-1$ 次乘法，故最后 $(a_n,b_n)$ 有 $\phi(c)=2^{n-1}$ 种可能。（通过构造过程可知$(a_{1\sim n},b_{1\sim n})$ 互不相同）</p>
<h3 id="2-3-小尾巴与结论"><a href="#2-3-小尾巴与结论" class="headerlink" title="2.3 小尾巴与结论"></a>2.3 小尾巴与结论</h3><p><strong>小尾巴：</strong><br>&emsp; 对比 $c_{n}=a_n^2+b_n^2$ 和 $2c=(s^{2}+t^{2})$ 仍有区别，此时将 $2 = 1^2+1^2$ 带入（*）中即可得到</p>
<script type="math/tex; mode=display">
\left\{\begin{array}{r}
s=a_{n}+b_{n} \\
t=a_{n}-b_{n}
\end{array}\right.</script><p>&emsp; 上式中，$s,t$为大于0的奇数，且 $(s,t)=1$  </p>
<p><strong>结论：</strong>  </p>
<ol>
<li>能够分解出本原勾股数组的 $c$ 的形式为 $c=\prod_{i=1}^n p_i^{\alpha_i}$（ 即$\beta_i=0$ ）。</li>
<li>对于$c=\prod_{i=1}^n p_i^{\alpha_i}$，可以分解出的不同本原勾股数组的组数 $\phi(c)=2^{n-1}$。</li>
</ol>
<p><strong>说明：</strong>  </p>
<ol>
<li>本文中的部分结论只证明了充分性没有证明必要性。</li>
<li>本文证明只涉及初等代数及数论，稍显冗杂。</li>
<li>markdown中公式表格的渲染还是弱了点。。另外整理时间较短，有点乱。</li>
</ol>
<h2 id="3-程序验证"><a href="#3-程序验证" class="headerlink" title="3 程序验证"></a>3 程序验证</h2><p>&emsp; Matlab 验证，程序参下：</p>
<figure class="highlight matlab"><table><tr><td class="code"><pre><span class="line"><span class="comment">% num   为/phi(c)的取值范围，</span></span><br><span class="line"><span class="comment">% ia    为/phi(c)对应的最小c值。</span></span><br><span class="line"><span class="comment">%</span></span><br><span class="line"><span class="comment">% con_in 行号为c，第一列为对应的本原勾股数组组数</span></span><br><span class="line"><span class="comment">%                 第二列开始，每两列分别为一组的s,t</span></span><br><span class="line"></span><br><span class="line">clear</span><br><span class="line">clc</span><br><span class="line"></span><br><span class="line">maxc =<span class="number">100000</span>; <span class="comment">%搜索的长度</span></span><br><span class="line">con_in = <span class="built_in">zeros</span>(maxc,<span class="number">33</span>); <span class="comment">% 组数容量32（可以估算）</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> c = <span class="number">1</span>:maxc     </span><br><span class="line">    <span class="comment">% s^2+t^2 = 2c</span></span><br><span class="line">    <span class="comment">%s 的搜索区间为（[sqrt(2c)]~[sqrt(c)]）   </span></span><br><span class="line">    lb = <span class="built_in">floor</span>(<span class="built_in">sqrt</span>(c));</span><br><span class="line">    rb = <span class="built_in">floor</span>(<span class="built_in">sqrt</span>(<span class="number">2</span>*c));</span><br><span class="line">    <span class="keyword">for</span> s = lb:rb</span><br><span class="line">        t = <span class="built_in">sqrt</span>(<span class="number">2</span>*c-s^<span class="number">2</span>);</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">rem</span>(t,<span class="number">2</span>) == <span class="number">1</span>)&amp;&amp;(<span class="built_in">gcd</span>(s,t) == <span class="number">1</span>)</span><br><span class="line">            con_in(c,<span class="number">1</span>) = con_in(c,<span class="number">1</span>)+<span class="number">1</span>;</span><br><span class="line">            con_in(c,<span class="number">2</span>*(con_in(c,<span class="number">1</span>))) = s;</span><br><span class="line">            con_in(c,<span class="number">2</span>*(con_in(c,<span class="number">1</span>))+<span class="number">1</span>) = t;           </span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">    <span class="keyword">end</span>  </span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line">[num,ia,index] = unique(con_in(:,<span class="number">1</span>));</span><br></pre></td></tr></table></figure>
<p>&emsp; 最后结果与前推导相符 :</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">本原勾股组数</th>
<th style="text-align:center">最小的c</th>
<th style="text-align:center">$p_i$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center">5</td>
<td style="text-align:center">5</td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center">65</td>
<td style="text-align:center">5x13</td>
</tr>
<tr>
<td style="text-align:center">4</td>
<td style="text-align:center">1105</td>
<td style="text-align:center">5x13x17</td>
</tr>
<tr>
<td style="text-align:center">8</td>
<td style="text-align:center">32045</td>
<td style="text-align:center">5x13x17x29</td>
</tr>
</tbody>
</table>
</div>
<h2 id="4-参考"><a href="#4-参考" class="headerlink" title="4 参考"></a>4 参考</h2><p>没啥参考</p>
]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>初等数论</tag>
        <tag>本原勾股数</tag>
      </tags>
  </entry>
  <entry>
    <title>高斯过程回归浅析</title>
    <url>/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B%E5%9B%9E%E5%BD%92%E6%B5%85%E6%9E%90/</url>
    <content><![CDATA[<p>&emsp; &emsp; 高斯过程回归（Gaussian Process Regression）是一种结合先验进行回归分析的非参数概率模型。利用高斯过程可以优雅的实现小样本回归，并且能够让人直观的感受回归效果，尤其是其优美的分布特性引人入胜，在笔者看来，是一个不错的预测回归工具。<br>&emsp; &emsp; 高斯过程在近几年也有不错的发展，关注到&ensp;Raissi (2017) 提出一种利用GPR绕过求解微分方程步骤，直接学习的方程中的系数的方法，可适用于例如扩散场求解等各种工程问题。本文将概述高斯过程核心理论，同时尝试代码实现利用高斯过程学习抛物线型微分方程的系数。<br><a id="more"></a><br>&emsp; &emsp; en 标题起的不太准，懒得改辽</p>
<h2 id="1-高斯过程简介"><a href="#1-高斯过程简介" class="headerlink" title="1 高斯过程简介"></a>1 高斯过程简介</h2><p>&emsp; 本部分将谈到多维高斯分布，边缘分布与条件分布，以及高斯过程的个人理解。从熟悉的一维高斯分布容易扩展到二维以及多维的高斯分布，推导及相关性质不再赘述，可参考：</p>
<ul>
<li><a href="https://www.cnblogs.com/jermmyhsu/p/8251013.html" target="_blank" rel="noopener">多维高斯分布推导</a>  </li>
</ul>
<h3 id="1-1-多维高斯分布"><a href="#1-1-多维高斯分布" class="headerlink" title="1.1 多维高斯分布"></a>1.1 多维高斯分布</h3><p>&emsp; 无论是一维高斯分布还是多维高斯分布，其分布特性都由均值向量和协方差矩阵确定。假设向量 𝑋 服从均值为向量 𝜇，协方差矩阵为 𝐾 的高斯分布，本文记为：</p>
<script type="math/tex; mode=display">X \sim \mathcal{N}(\mu, K)</script><p>&emsp; 上式中向量 𝑋 由随机变量组成（每一个随机变量都服从正态分布，因而随机变量的联合分布也是属于高斯分布的），均值向量 𝜇 描述的是向量 𝑋 的分布的期望，而协方差矩阵 𝐾 用以记录描述每个随机变量之间的关联，是一个对称的半正定矩阵:</p>
<script type="math/tex; mode=display">K=\operatorname{Cov}\left(x_{i}, x_{j}\right)=E\left[\left(x_{i}-\mu_{i}\right)\left(x_{j}-\mu_{j}\right)\right]</script><h3 id="1-2-高斯分布的边缘与条件分布"><a href="#1-2-高斯分布的边缘与条件分布" class="headerlink" title="1.2 高斯分布的边缘与条件分布"></a>1.2 高斯分布的边缘与条件分布</h3><p>&emsp; 由于高斯过程回归会应用到贝叶斯公式计算后验概率，因此需要考虑随机变量的条件分布与边缘分布的计算。推导过程可参考：  </p>
<ul>
<li><a href="http://fourier.eng.hmc.edu/e161/lectures/gaussianprocess/node7.html" target="_blank" rel="noopener">Marginal and conditional distributions of multivariate normal distribution</a></li>
<li><a href="https://blog.csdn.net/denalmighty/article/details/81090311" target="_blank" rel="noopener">边缘与条件分布推导</a>  </li>
<li><a href="https://www.jiqizhixin.com/articles/2018-02-16" target="_blank" rel="noopener">贝叶斯计算推导（附录A）</a>  </li>
</ul>
<p>&emsp; 不出意外，高斯分布的条件分布与边缘分布仍然是高斯分布，这是最最最吸引笔者的地方，此外也贝叶斯推断变得容易求解。</p>
<p>若假设随机变量 X, Y 的联合分布服从高斯分布:</p>
<script type="math/tex; mode=display">\left[\begin{array}{l}
X \\
Y
\end{array}\right] \sim \mathcal{N}(\mu, K)=\mathcal{N}\left(\left[\begin{array}{l}
\mu_{X} \\
\mu_{Y}
\end{array}\right],\left[\begin{array}{ll}
K_{X X} & K_{X Y} \\
K_{Y X} & K_{Y Y}
\end{array}\right]\right)</script><p>那么条件概率的计算公式为：</p>
<script type="math/tex; mode=display">X \mid Y \sim \mathcal{N}\left(\mu_{X}+K_{X Y} K_{Y Y}^{-1}\left(Y-\mu_{Y}\right), K_{X X}-K_{X Y} K_{Y Y}^{-1} K_{Y X}\right)</script><p>此时将联合概率分布对要边缘化的随机变量进行积分，可以计算出边缘概率分布：</p>
<script type="math/tex; mode=display">p_{X}(x)=\int p_{X, Y}(x, y) d y=\int p_{X \mid Y}(x \mid y) p_{Y}(y) d y</script><p>由上式计算可得：</p>
<script type="math/tex; mode=display">\begin{array}{l}
X \sim \mathcal{N}\left(\mu_{X}, K_{X X}\right) \\
Y \sim \mathcal{N}\left(\mu_{Y}, K_{Y Y}\right)
\end{array}</script><h3 id="1-3-高斯过程概述"><a href="#1-3-高斯过程概述" class="headerlink" title="1.3 高斯过程概述"></a>1.3 高斯过程概述</h3><p>&emsp; 高斯过程可以看作是高斯分布从离散域到连续域的扩展，是一种由有限维度到无限维度的延伸。随着维度的升高，可以看作随机变量 X 由是由函数𝑓(𝑥) 采样得到的，那么原来的高斯分布就变为：</p>
<script type="math/tex; mode=display">f(x)=\left[f\left(x_{1}\right), f\left(x_{1}\right), \ldots, f\left(x_{n}\right)\right] \sim \mathcal{N}\left(\mu_{x}, K_{x}\right)</script><p>若对于定义域内的所有的 𝑥∈𝐷 上式都成立则称 𝑓 是一个高斯过程，表示为：</p>
<script type="math/tex; mode=display">f  \sim G \mathcal{P}(\mu(x), k(x, x))</script><p>上式中，𝜇(𝑥) 表示均值函数（Mean Function），𝑘(𝑥,𝑥) 为协方差函数（Covariance Function），常用核函数表示，本质上是描述随机变量之间相互影响的函数。</p>
<h2 id="2-基于GPR的Raissi方法实现"><a href="#2-基于GPR的Raissi方法实现" class="headerlink" title="2 基于GPR的Raissi方法实现"></a>2 基于GPR的Raissi方法实现</h2><p>&emsp; 直接的高斯过程回归十分优雅，按照笔者的理解，这是一个利用采样信息去计算贝叶斯后验概率的过程。而关于普通的高斯过程回归（或者分类）的实现，无论是自己敲点代码还是利用如matlab工具箱、SKlearn等现成工具包，都能较为方便完成。直接的高斯过程回归的理解与实现可参考：</p>
<ul>
<li><a href="https://www.jgoertler.com/visual-exploration-gaussian-processes/" target="_blank" rel="noopener">高斯过程回归直观理解（推荐）</a></li>
<li><a href="https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html#" target="_blank" rel="noopener">SKlearn-GPR 官方文档（用SKlearn必读）</a></li>
<li><a href="https://blog.dominodatalab.com/fitting-gaussian-process-models-python/" target="_blank" rel="noopener">自己coding可参考</a></li>
</ul>
<p>&emsp; 值得注意的是，直接的高斯过程回归可以进行核函数优化以得到更好的概率分布。而 Raissi 在 2017年提出利用参数优化过程结合高斯过程的分布特点，实现抛物线型微分方程参数的传递与求解的方法。下文将尝试实现这一方法。</p>
<h3 id="2-1-核函数"><a href="#2-1-核函数" class="headerlink" title="2.1 核函数"></a>2.1 核函数</h3><p>&emsp;常见的基本核函数（kernel function）有径向基函数核、周期核、线性核、常数核等。这些核函数都有各自的特性，比如径向基函数核为平稳核，协方差矩阵只取决于随机变量的相对位置；周期核函数顾名思义具有周期性，协方差矩阵沿对角线将会出现规律性分布。本章采取的核函数为径向基函数核：</p>
<script type="math/tex; mode=display">k_{u u}\left(x, x^{\prime} ; \theta\right)=\sigma^{2} \exp \left(-\frac{1}{2} \sum_{i=1}^{N} w_{i}\left(x_{i}-x_{i}^{\prime}\right)^{2}\right)</script><p>上式中, $\theta=\left(\sigma, w_{d}^{i}\right)$ 为核函数的超参数（hyper parameter），$w_{d}$ 为自动相关确定权重（Automatic Relevance Determination, 简称ARD）。直观上$w_{i}$ 影响高斯分布的平滑程度，超参数 σ 将影响高斯分布与均值之间的距离. </p>
<div align="center">
<img src="/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B%E5%9B%9E%E5%BD%92%E6%B5%85%E6%9E%90/2.1c.jpg"> <img src="/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B%E5%9B%9E%E5%BD%92%E6%B5%85%E6%9E%90/2.1d.jpg">
</div>

<p>&emsp;如图，淡蓝色区间为高斯过程的置信区间，蓝色实现为高斯过程的均值分布。可以看出随着$w_{i}$的增加，高斯过程更加平滑；随着超参数σ的减小，高斯过程分布更加集中。<br>&emsp; 利用高斯过程在贝叶斯最大化后验概率中学习超参数的值，该方法采用L-BFGS算法求解对数边缘似然的最大值，也就是：</p>
<script type="math/tex; mode=display">\max \left\{\log p(y \mid \phi, \theta)=\frac{1}{2} \log |K|+\frac{1}{2} y^{T} K^{-1} y+\frac{N}{2} \log (2 \pi)\right\}</script><p>&emsp; 需要说明的是，后验概率随超参数的分布是一个非凸问题，如果优化初值设置不合理，会陷入局部最优，且在没有先验知识的情况下难以对超参数的初值进行估计与调整，目前常用的有效方法还是通过改变初值重复计算来尽量找寻最优解。此时观察可知，核函数 K 的计算是整个问题的核心所在。</p>
<h3 id="2-2-一维扩散方程"><a href="#2-2-一维扩散方程" class="headerlink" title="2.2 一维扩散方程"></a>2.2 一维扩散方程</h3><p>由菲克定律，渗透扩散问题的线性偏微分微分方程的形式为：</p>
<script type="math/tex; mode=display">\begin{array}{l}
f(x, t)=\mathcal{L}_{x}^{D} u=0 \\
\mathcal{L}_{x}^{D}=\frac{\partial}{\partial t}-D \frac{\partial^{2}}{\partial x^{2}}
\end{array}</script><p>若假设函数 𝑢 是一个高斯过程：</p>
<script type="math/tex; mode=display">u \sim \mathcal{G} \mathcal{P}\left(\mu(x)=0, k_{u u}(x, x)\right)</script><p>那么函数 𝑢 经过线性过程得到的函数 𝑓(𝑥,𝑡) 也是一个高斯过程：</p>
<script type="math/tex; mode=display">f \sim \mathcal{G} \mathcal{P}\left(\mu(x)=0, k_{f f}(x, x)\right)</script><p>核函数 $k_{u u}(x, x)$ 与核函数 $k_{f f}(x, x)$ 之间的关系为：</p>
<script type="math/tex; mode=display">k_{f f}(x 1, x 2)=\mathcal{L}_{x 1}^{D} \mathcal{L}_{x 2}^{D} k_{u u}(x 1, x 2)</script><p>$k_{f f}(x, x)$描述了函数 𝑓 与函数 𝑓 之间的分布关系，同样的函数 𝑓 与函数 𝑢 的关系，函数 𝑢 与函数 𝑓 的关系可以表示为：</p>
<script type="math/tex; mode=display">\begin{array}{l}
k_{f u}(x 1, x 2)=\mathcal{L}_{x 1}^{D} k_{u u}(x 1, x 2) \\
k_{u f}(x 1, x 2)=\mathcal{L}_{x 2}^{D} k_{u u}(x 1, x 2)
\end{array}</script><p>此时考虑函数 𝑓 与函数 𝑢 的联合分布𝑋=[𝑓,𝑢]，𝑋服从高斯分布，其协方差矩阵为：</p>
<script type="math/tex; mode=display">K=\left[\begin{array}{cc}
k_{u u}+\sigma_{u} & k_{u f} \\
k_{f u} & k_{f f}+\sigma_{f}
\end{array}\right]</script><p>其中，$\sigma_{u}$、$\sigma_{f}$ 为函数 𝑢 与函数 𝑓 的采样噪声估计，不难看出，若 $k_{u u}$采用上述的径向基核函数，那么上式的超参数为：</p>
<script type="math/tex; mode=display">\theta=\left(D, \sigma, w_{i}, \sigma_{u,}, \sigma_{f}\right)</script><p>至此，计算得到了一维扩散问题的核函数K，结合上一节，通过超参数优化过程，可以求解最合理的扩散系数D，完成扩散方程的参数学习。</p>
<h3 id="2-3-处理细节"><a href="#2-3-处理细节" class="headerlink" title="2.3 处理细节"></a>2.3 处理细节</h3><p>&emsp; 到目前为止，理论上能够计算抛物线型微分方程中的系数，但是离代码实现与工程应用还有两点细节处理，一个是核函数的代码计算方式在参数传递之后变得尤为复杂，另一个是回归过程的采样数据难以获取（很难测得渗透内部的时刻浓度）。</p>
<h4 id="2-3-1-理论模型修改"><a href="#2-3-1-理论模型修改" class="headerlink" title="2.3.1 理论模型修改"></a>2.3.1 理论模型修改</h4><p>&emsp; 用 Fick定律进行分析对原微分方程进行改造以适合工程实际。</p>
<script type="math/tex; mode=display">\begin{array}{l}
\because J=-D \frac{\partial C}{\partial x} \quad \therefore \quad \frac{\partial J}{\partial t}=-D \frac{\partial^{2} C}{\partial x \partial t} \\
\therefore \quad \frac{\partial^{2} J}{\partial x^{2}}=\frac{\partial}{\partial x}\left(\frac{\partial J}{\partial x}\right)=\frac{\partial}{\partial x}\left(-D \frac{\partial^{2} C}{\partial x^{2}}\right)
\end{array}</script><p>带入Fick第二定律中有：</p>
<script type="math/tex; mode=display">\frac{\partial^{2} J}{\partial x^{2}}=\frac{\partial}{\partial x}\left(-D \frac{1}{D} \frac{\partial C}{\partial t}\right)=-\frac{\partial^{2} C}{\partial x \partial t}</script><p>对比可以得到：</p>
<script type="math/tex; mode=display">\frac{\partial J}{\partial t}-D \frac{\partial^{2} J}{\partial x^{2}}=0</script><p>此时，原微分方程转化为：</p>
<script type="math/tex; mode=display">\mathcal{L}_{x}^{D}=\frac{\partial}{\partial t}-D \frac{\partial^{2}}{\partial x^{2}} \quad u=J</script><p>&emsp;工程实际中，出口的渗透速率容易测量，此时整个扩散问题的处理方法才具备应用价值。</p>
<h4 id="2-3-2-核函数计算"><a href="#2-3-2-核函数计算" class="headerlink" title="2.3.2 核函数计算"></a>2.3.2 核函数计算</h4><p>&emsp;笔者在代码实现过程中，尝试过用计算微分的函数包简化核函数计算，遗憾未实现（看官有好的建议一定一定告诉我！），故而一定程度上简化原核函数并采取暴力计算，公式推导结果如下：</p>
<script type="math/tex; mode=display">k_{u u}=\sigma^{2} \exp \left(-\frac{d^{2}}{2 l_{x, t}^{2}}\right)=k, d^{2}=\left(x-x^{\prime}\right)^{2}+\left(t-t^{\prime}\right)^{2}</script><script type="math/tex; mode=display">\left\{\begin{array}{c}
k_{u f}=\frac{\partial k}{\partial t^{\prime}}-D \frac{\partial^{2} k}{\partial x^{\prime 2}} \\
k_{f u}=\frac{\partial k}{\partial t}-D \frac{\partial^{2} k}{\partial x^{2}} \\
k_{f f}=\frac{\partial^{2} k}{\partial t \partial t^{\prime}}-D\left(\frac{\partial^{3} k}{\partial x^{2} \partial t^{\prime}}+\frac{\partial^{3} k}{\partial x^{\prime 2} \partial t}\right)+D^{2} \frac{\partial^{4} k}{\partial x^{2} \partial x^{\prime 2}}
\end{array}\right.</script><p>上述式子中，笔者计算的各阶偏导数为：</p>
<script type="math/tex; mode=display">\frac{\partial k}{\partial t}=-\frac{\partial k}{\partial t^{\prime}}=-k \frac{t-t^{\prime}}{l_{t}^{2}}</script><script type="math/tex; mode=display">\frac{\partial^{2} k}{\partial x^{2}}=\frac{\partial^{2} k}{\partial x^{\prime 2}}=k\left(\frac{x-x^{\prime}}{l_{x}^{2}}\right)^{2}-\frac{k}{l_{x}^{2}}</script><script type="math/tex; mode=display">\frac{\partial^{2} k}{\partial t \partial t^{\prime}}=-k\left(\frac{t-t^{\prime}}{l_{t}^{2}}\right)^{2}+\frac{k}{l_{t}^{2}}</script><script type="math/tex; mode=display">\frac{\partial^{3} k}{\partial x^{2} \partial t^{\prime}}=-\frac{\partial^{3} k}{\partial x^{\prime 2} \partial t}=k\left[\left(\frac{x-x^{\prime}}{l_{x}^{2}}\right)^{2}-\frac{1}{l_{x}^{2}}\right] \frac{t-t^{\prime}}{l_{t}^{2}}</script><script type="math/tex; mode=display">\frac{\partial^{4} k}{\partial x^{2} \partial x^{\prime 2}}=k\left[\frac{\left(x-x^{\prime}\right)^{4}}{l_{x}^{6}}-\frac{6\left(x-x^{\prime}\right)^{2}}{l_{x}^{6}}+\frac{3}{l_{x}^{6}}\right]</script><p>此时，超参数为：$\theta=\left(D, \sigma, l_{x}, l_{t}, \sigma_{u, f}\right)$</p>
<h3 id="2-4-代码实现结果"><a href="#2-4-代码实现结果" class="headerlink" title="2.4 代码实现结果"></a>2.4 代码实现结果</h3><p>&emsp;笔者迁移 sklearn 中高斯过程的实现模式，模仿其接口风格，完成了适用于RBF核为基本核，线性算子为上文中 $\mathcal{L}_{x}^{D}$ 的高斯过程回归(二维)。代码整理后将发布到 github，或者欢迎邮件联系。</p>
<h4 id="2-4-1-超参数取值空间优化"><a href="#2-4-1-超参数取值空间优化" class="headerlink" title="2.4.1 超参数取值空间优化"></a>2.4.1 超参数取值空间优化</h4><p>&emsp; 前文已述，超参数优化是个非凸问题，而核函数计算又比较复杂，初值选取不当很容易导致优化问题无解，所以笔者先用控制变量法手动调节超参数学习初始值，凭借一定经验判断较为合理的超参数优化区间，如下图可观察优化过程：</p>
<div align="center">
<img src="/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B%E5%9B%9E%E5%BD%92%E6%B5%85%E6%9E%90/2.2.jpg">  
</div>

<p>图中（a）到（b）优化了长度尺寸超参数 $𝑙_{𝑥}$ ，由（b）到（c）优化了时间尺寸超参数 $𝑙_{𝑡}$ ，由（c）到（d）优化了增益 𝜎 与噪声评价超参数 $\sigma_{u, f}$。如图可见，随着超参数优化区间的调整，拟合曲面逐渐平坦且合理，虽然依照经验调整无法达到最优区间甚至导致过拟合，但是作为超参数的取值区间，只要后续超参数优化时不碰到区间边界即可减少主观影响。超参数优化过程可继续深入研究。</p>
<h4 id="2-4-2-高斯过程预测"><a href="#2-4-2-高斯过程预测" class="headerlink" title="2.4.2 高斯过程预测"></a>2.4.2 高斯过程预测</h4><p>&emsp; 高斯过程回归经过参数优化之后，能够对核函数影响区间内的采样点做出预测，预测原理为通过训练点计算后验概率，若只关注微分方程中的系数其实不用进行预测，但是高斯过程预测能够直观观察回归情况，计算方式为：</p>
<script type="math/tex; mode=display">u_{p} \sim \mathcal{N}\left(\bar{u}_{p}, s_{u}^{2}\right)</script><script type="math/tex; mode=display">\bar{u}_{p}=P K^{-1} Y, \quad s_{u}^{2}=k_{u u}\left(x_{p}, x_{p}\right)-P K^{-1} P^{T}</script><p>式中：$P=\left[k_{u u}\left(x_{p}, x_{u}\right) \quad k_{u f}\left(x_{p}, x_{f}\right)\right]$ ,&emsp;$Y=\left[u\left(x_{u}\right) f\left(x_{f}\right)\right]$</p>
<p>&emsp;通过差分仿真获取微分方程理论数据进行回归对比，随机采样扩散前期数据（40 points）进行学习，得到的回归预测分布如图：</p>
<div align="center">
<img src="/%E9%AB%98%E6%96%AF%E8%BF%87%E7%A8%8B%E5%9B%9E%E5%BD%92%E6%B5%85%E6%9E%90/2.3.jpg">  
</div>

<p>图中微分方程系数的学习误差为 3.7%，有不错的精度。</p>
<h2 id="3-总结"><a href="#3-总结" class="headerlink" title="3. 总结"></a>3. 总结</h2><p>&emsp;直接的高斯过程回归目前已经发展的相对成熟，应用范围广，主要是形式好看十分吸引笔者。此处推荐两本相对容易入门的书（我也只看了一点）  </p>
<p><em>推荐阅读</em>  </p>
<p><a href="/部分书目下载/index.html"><em>C.E. Rasmussen. Gaussian processes in machine learning.</em></a><br><em>K.P. Murphy. Machine learning: a probabilistic perspective.</em>  </p>
<p>&emsp;按照论文，笔者基本实现Raissi方法。由于初值选取有点玄，我调参经验也不是很足，不能达到Raissi（2017）中同样方程的精度，此外有以下不足：  </p>
<ul>
<li>计算精度严重依赖初值，并且容易陷入局部最优，奇异矩阵中断求解等情况。Raissi在文中也提到采用合适的数据能得到很好的处理结果。所以我对这种方法的工程实际应用存疑，对论文中极其理想的结果也有一定怀疑。  </li>
<li>对于不同的方程，核函数的计算要重新构造，需要新的计算方式简化核函数的微分。</li>
<li>直接的高斯过程能够实现采样点覆盖范围内的预测，但是在远离采样的地方，难以影响协方差矩阵，笔者认为原理上是不能实现有效预测的，要实现前期样本预测后期数据分布等功能，需要加入如Raissi方法依赖的微分方程等先验知识。</li>
</ul>
<p>此外，高斯过程计算空间复杂度较高，实现大样本的高斯过程回归有助于提高模型稳定性，可继续研究。</p>
]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>Gaussian process</tag>
        <tag>GPR</tag>
        <tag>核函数</tag>
      </tags>
  </entry>
  <entry>
    <title>部分书目下载</title>
    <url>/%E9%83%A8%E5%88%86%E4%B9%A6%E7%9B%AE%E4%B8%8B%E8%BD%BD/</url>
    <content><![CDATA[<p>some books or articles<br><a id="more"></a></p>
<ol>
<li><a href="/download/GPfML.pdf">C.E. Rasmussen. Gaussian processes in machine learning</a></li>
<li><a href="/download/[Algorithms%20for%20Decision%20Making].pdf">Algorithms for Decision Making</a></li>
</ol>
]]></content>
      <categories>
        <category>source</category>
      </categories>
  </entry>
</search>
